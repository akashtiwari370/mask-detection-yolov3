{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfafe56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32e13bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive C is Windows\n",
      " Volume Serial Number is BCC9-B33E\n",
      "\n",
      " Directory of C:\\Users\\Aki\\Desktop\\yolo-custom-object-detection\n",
      "\n",
      "07/22/2021  02:05 PM    <DIR>          .\n",
      "07/21/2021  09:02 PM    <DIR>          ..\n",
      "07/22/2021  12:08 AM    <DIR>          .ipynb_checkpoints\n",
      "07/22/2021  12:04 AM                30 classes.txt\n",
      "07/16/2021  07:12 PM               703 coco.names\n",
      "07/21/2021  11:34 PM        87,015,623 images.zip\n",
      "07/21/2021  09:06 PM    <DIR>          Single-Multiple-Custom-Object-Detection\n",
      "07/22/2021  11:23 AM             5,068 video_objectDetection.ipynb\n",
      "07/22/2021  12:04 AM             8,337 yolov3_testing.cfg\n",
      "07/22/2021  12:58 PM       246,326,928 yolov3_training_final.weights\n",
      "07/22/2021  07:30 AM       246,326,928 yolov3_training_last.weights\n",
      "               7 File(s)    579,683,617 bytes\n",
      "               4 Dir(s)  66,987,581,440 bytes free\n"
     ]
    }
   ],
   "source": [
    "%ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82591880",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = cv2.dnn.readNet('yolov3_training_final.weights','yolov3_testing.cfg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f651d99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = []\n",
    "\n",
    "with open('classes.txt','r') as f:\n",
    "    classes = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "107b405e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c239e2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    ret,img= cap.read()\n",
    "    height,width, _ = img.shape\n",
    "    blob = cv2.dnn.blobFromImage(img, 1/255, (416,416), (0,0,0), swapRB=True, crop=False)\n",
    "\n",
    "    net.setInput(blob)\n",
    "\n",
    "    output_layers_names = net.getUnconnectedOutLayersNames()\n",
    "    layersOutput = net.forward(output_layers_names)\n",
    "    boxes=[]\n",
    "    confidences=[]\n",
    "    class_ids=[]\n",
    "    for output in layersOutput:\n",
    "        for detection in output:\n",
    "            scores=detection[5:]\n",
    "            class_id = np.argmax(scores)\n",
    "            confidence=scores[class_id]\n",
    "            if confidence > 0.5:\n",
    "                center_x=int(detection[0]*width)\n",
    "                center_y = int(detection[1]*height)\n",
    "                w = int(detection[2]*width)\n",
    "                h = int(detection[3]*height)\n",
    "\n",
    "                x = int(center_x - w/2) \n",
    "                y = int(center_y - h/2)\n",
    "\n",
    "                boxes.append([x,y,w,h])\n",
    "                confidences.append((float(confidence)))\n",
    "                class_ids.append(class_id)\n",
    "\n",
    "\n",
    "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "\n",
    "    font = cv2.FONT_HERSHEY_PLAIN\n",
    "    colors = np.random.uniform(0, 255, size=(len(boxes),3))\n",
    "    try:\n",
    "        for i in indexes.flatten():\n",
    "            x,y,w,h = boxes[i]\n",
    "            label=str(classes[class_ids[i]])\n",
    "            confidence=str(round(confidences[i],2))\n",
    "            color = colors[i]\n",
    "            cv2.rectangle(img, (x,y), (x+w, y+h), color, 2)\n",
    "            cv2.putText(img, label + \" \" + confidence, (x, y+20), font, 2, (255,255,255),2)\n",
    "        cv2.imshow('Image',img)\n",
    "        if cv2.waitKey(10)==13:\n",
    "            break\n",
    "    except:\n",
    "        cv2.imshow('Image',img)\n",
    "        if cv2.waitKey(10)==13:\n",
    "            break\n",
    "        \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63d3447c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cebd6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
